name: "ResNet-44"
layer {
	name: "cifar"
	type: "Data"
	top: "data"
	top: "label"
	include {
		phase: TRAIN
	}
	transform_param {
		mean_file: "examples/cifar10/mean.binaryproto"
		mirror: 1
		crop_size: 28
	}
	data_param {
		source: "examples/cifar10/cifar10_train_lmdb"
		batch_size: 80
		backend: LMDB
	}
}
layer {
	name: "cifar"
	type: "Data"
	top: "data"
	top: "label"
	include {
		phase : TEST
	}
	transform_param {
		mean_file: "examples/cifar10/mean.binaryproto"
	}
	data_param {
		source: "examples/cifar10/cifar10_test_lmdb"
		batch_size: 1
		backend: LMDB
	}
}

layer {
	bottom: "data"
	top: "conv1"
	name: "conv1"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 4
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv1"
	top: "conv1"
	name: "bn_conv1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv1"
	top: "conv1"
	name: "bn_conv1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale1"
	type: "Scale"
	bottom: "conv1"
	top: "conv1"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "conv1"
	top: "conv1"
	name: "conv1_relu"
	type: "ReLU"
}

#####------- Residual Block 1 ---------#####

layer {
	bottom: "conv1"
	top: "conv2"
	name: "conv2"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv2"
	top: "conv2"
	name: "bn_conv2"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv2"
	top: "conv2"
	name: "bn_conv2"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale2"
	type: "Scale"
	bottom: "conv2"
	top: "conv2"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "conv2"
	top: "conv2"
	name: "conv2_relu"
	type: "ReLU"
}

layer {
	bottom: "conv2"
	top: "conv3"
	name: "conv3"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		#bias_filler {
		#	type: "constant"
		#	value: 0.2
		#}
	}
}

layer {
	bottom: "conv3"
	top: "conv3"
	name: "bn_conv3"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv3"
	top: "conv3"
	name: "bn_conv3"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale3"
	type: "Scale"
	bottom: "conv3"
	top: "conv3"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "conv1"
	bottom: "conv3"
	top: "res1"
	name: "res1"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 2 ---------#####

layer {
	bottom: "res1"
	top: "conv4"
	name: "conv4"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv4"
	top: "conv4"
	name: "bn_conv4"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv4"
	top: "conv4"
	name: "bn_conv4"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale4"
	type: "Scale"
	bottom: "conv4"
	top: "conv4"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "conv4"
	top: "conv4"
	name: "conv4_relu"
	type: "ReLU"
}

layer {
	bottom: "conv4"
	top: "conv5"
	name: "conv5"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv5"
	top: "conv5"
	name: "bn_conv5"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv5"
	top: "conv5"
	name: "bn_conv5"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale5"
	type: "Scale"
	bottom: "conv5"
	top: "conv5"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res1"
	bottom: "conv5"
	top: "res2"
	name: "res2"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 3 ---------#####

layer {
	bottom: "res2"
	top: "conv6"
	name: "conv6"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv6"
	top: "conv6"
	name: "bn_conv6"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv6"
	top: "conv6"
	name: "bn_conv6"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale6"
	type: "Scale"
	bottom: "conv6"
	top: "conv6"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "conv6"
	top: "conv6"
	name: "conv6_relu"
	type: "ReLU"
}

layer {
	bottom: "conv6"
	top: "conv7"
	name: "conv7"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv7"
	top: "conv7"
	name: "bn_conv7"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv7"
	top: "conv7"
	name: "bn_conv7"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale7"
	type: "Scale"
	bottom: "conv7"
	top: "conv7"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res2"
	bottom: "conv7"
	top: "res3"
	name: "res3"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 4 ---------#####

layer {
	bottom: "res3"
	top: "conv8"
	name: "conv8"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv8"
	top: "conv8"
	name: "bn_conv8"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv8"
	top: "conv8"
	name: "bn_conv8"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale8"
	type: "Scale"
	bottom: "conv8"
	top: "conv8"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "conv8"
	top: "conv8"
	name: "conv8_relu"
	type: "ReLU"
}

layer {
	bottom: "conv8"
	top: "conv9"
	name: "conv9"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv9"
	top: "conv9"
	name: "bn_conv9"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv9"
	top: "conv9"
	name: "bn_conv9"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale9"
	type: "Scale"
	bottom: "conv9"
	top: "conv9"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res3"
	bottom: "conv9"
	top: "res4"
	name: "res4"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Inception Block 5 ---------#####

layer {
	bottom: "res4"
	top: "act9"
	name: "bn_conv10"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res4"
	top: "act9"
	name: "bn_conv10"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale10"
	type: "Scale"
	bottom: "act9"
	top: "act9"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act9"
	top: "act9"
	name: "conv10_relu"
	type: "ReLU"
}

layer {
	bottom: "act9"
	top: "inception5_conv1x1"
	name: "inception5_conv1x1"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception5_conv1x1"
	top: "inception5_conv1x1"
	name: "inception5_conv1x1_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act9"
	top: "inception5_3x3_reduce"
	name: "inception5_3x3_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception5_3x3_reduce"
	top: "inception5_3x3_reduce"
	name: "inception5_3x3_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act9"
	top: "inception5_5x5_reduce"
	name: "inception5_5x5_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 4
		pad: 2
		stride: 1
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception5_5x5_reduce"
	top: "inception5_5x5_reduce"
	name: "inception5_5x5_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act9"
	top: "inception5_pool"
	type: "Pooling"
	name: "inception5_pool"
	pooling_param {
		pool: MAX
		kernel_size: 3
		stride:1
		pad: 1
	}
}

layer {
	bottom: "inception5_3x3_reduce"
	top: "inception5_3x3"
	name: "inception5_3x3"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception5_3x3"
	top: "inception5_3x3"
	name: "inception5_3x3_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception5_5x5_reduce"
	top: "inception5_5x5"
	name: "inception5_5x5"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 8
		kernel_size: 5
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception5_5x5"
	top: "inception5_5x5"
	name: "inception5_5x5_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception5_pool"
	top: "inception5_pool_proj"
	name: "inception5_pool_proj"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 8
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception5_pool_proj"
	top: "inception5_pool_proj"
	name: "inception5_pool_proj_ReLU"
	type: "ReLU"
}

layer {
  name: "inception5_output"
  type: "Concat"
  bottom: "inception5_conv1x1"
  bottom: "inception5_3x3"
  bottom: "inception5_5x5"
  bottom: "inception5_pool_proj"
  top: "inception5_output"
}

layer {
	bottom: "inception5_output"
	top: "res5_inc_output"
	name: "res5_inc_output"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		pad: 0
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		#bias_filler {
		#	type: "constant"
		#	value: 0.2
		#}
	}
}

layer {
	bottom: "res4"
	bottom: "res5_inc_output"
	top: "res5"
	name: "res5"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 6 ---------#####

layer {
	bottom: "res5"
	top: "conv12"
	name: "conv12"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv12"
	top: "conv12"
	name: "bn_conv12"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv12"
	top: "conv12"
	name: "bn_conv12"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}


layer {
	name: "BN_scale12"
	type: "Scale"
	bottom: "conv12"
	top: "conv12"
	scale_param {
		bias_term: true
	}
}
layer {
	bottom: "conv12"
	top: "conv12"
	name: "conv12_relu"
	type: "ReLU"
}

layer {
	bottom: "conv12"
	top: "conv13"
	name: "conv13"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv13"
	top: "conv13"
	name: "bn_conv13"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv13"
	top: "conv13"
	name: "bn_conv13"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}


layer {
	name: "BN_scale13"
	type: "Scale"
	bottom: "conv13"
	top: "conv13"
	scale_param {
		bias_term: true
	}
}
layer {
	bottom: "res5"
	bottom: "conv13"
	top: "res6"
	name: "res6"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 7 ---------#####

layer {
	bottom: "res6"
	top: "conv14"
	name: "conv14"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv14"
	top: "conv14"
	name: "bn_conv14"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv14"
	top: "conv14"
	name: "bn_conv14"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}


layer {
	name: "BN_scale14"
	type: "Scale"
	bottom: "conv14"
	top: "conv14"
	scale_param {
		bias_term: true
	}
}
layer {
	bottom: "conv14"
	top: "conv14"
	name: "conv14_relu"
	type: "ReLU"
}

layer {
	bottom: "conv14"
	top: "conv15"
	name: "conv15"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv15"
	top: "conv15"
	name: "bn_conv15"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv15"
	top: "conv15"
	name: "bn_conv15"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}


layer {
	name: "BN_scale15"
	type: "Scale"
	bottom: "conv15"
	top: "conv15"
	scale_param {
		bias_term: true
	}
}
layer {
	bottom: "res6"
	bottom: "conv15"
	top: "res7"
	name: "res7"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 8 ---------#####

layer {
	bottom: "res7"
	top: "in_res8"
	name: "conv8_1"
	type: "Convolution"
	convolution_param {
		num_output: 32
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
		weight_filler {
			type: "gaussian"
			std: 0.25
			#std:0.02
		}
	}
}

layer {
	bottom: "res7"
	top: "conv16"
	name: "conv16"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 2
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv16"
	top: "conv16"
	name: "bn_conv16"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv16"
	top: "conv16"
	name: "bn_conv16"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}


layer {
	name: "BN_scale16"
	type: "Scale"
	bottom: "conv16"
	top: "conv16"
	scale_param {
		bias_term: true
	}
}
layer {
	bottom: "conv16"
	top: "conv16"
	name: "conv16_relu"
	type: "ReLU"
}

layer {
	bottom: "conv16"
	top: "conv17"
	name: "conv17"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv17"
	top: "conv17"
	name: "bn_conv17"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv17"
	top: "conv17"
	name: "bn_conv17"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}


layer {
	name: "BN_scale17"
	type: "Scale"
	bottom: "conv17"
	top: "conv17"
	scale_param {
		bias_term: true
	}
}
layer {
	bottom: "in_res8"
	bottom: "conv17"
	top: "res8"
	name: "res8"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 9 ---------#####

layer {
	bottom: "res8"
	top: "conv18"
	name: "conv18"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv18"
	top: "conv18"
	name: "bn_conv18"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv18"
	top: "conv18"
	name: "bn_conv18"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}


layer {
	name: "BN_scale18"
	type: "Scale"
	bottom: "conv18"
	top: "conv18"
	scale_param {
		bias_term: true
	}
}
layer {
	bottom: "conv18"
	top: "conv18"
	name: "conv18_relu"
	type: "ReLU"
}

layer {
	bottom: "conv18"
	top: "conv19"
	name: "conv19"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv19"
	top: "conv19"
	name: "bn_conv19"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv19"
	top: "conv19"
	name: "bn_conv19"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}


layer {
	name: "BN_scale19"
	type: "Scale"
	bottom: "conv19"
	top: "conv19"
	scale_param {
		bias_term: true
	}
}
layer {
	bottom: "res8"
	bottom: "conv19"
	top: "res9"
	name: "res9"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 10 ---------#####

layer {
	bottom: "res9"
	top: "conv20"
	name: "conv20"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv20"
	top: "conv20"
	name: "bn_conv20"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv20"
	top: "conv20"
	name: "bn_conv20"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale20"
	type: "Scale"
	bottom: "conv20"
	top: "conv20"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "conv20"
	top: "conv20"
	name: "conv20_relu"
	type: "ReLU"
}

layer {
	bottom: "conv20"
	top: "conv21"
	name: "conv21"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv21"
	top: "conv21"
	name: "bn_conv21"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv21"
	top: "conv21"
	name: "bn_conv21"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale21"
	type: "Scale"
	bottom: "conv21"
	top: "conv21"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "res9"
	bottom: "conv21"
	top: "res10"
	name: "res10"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 11 ---------#####

layer {
	bottom: "res10"
	top: "conv22"
	name: "conv22"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv22"
	top: "conv22"
	name: "bn_conv22"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv22"
	top: "conv22"
	name: "bn_conv22"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale22"
	type: "Scale"
	bottom: "conv22"
	top: "conv22"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "conv22"
	top: "conv22"
	name: "conv22_relu"
	type: "ReLU"
}

layer {
	bottom: "conv22"
	top: "conv23"
	name: "conv23"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res10"
	bottom: "conv23"
	top: "res11"
	name: "res11"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 12 ---------#####

layer {
	bottom: "res11"
	top: "act23"
	name: "bn_conv24"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res11"
	top: "act23"
	name: "bn_conv24"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale24"
	type: "Scale"
	bottom: "act23"
	top: "act23"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act23"
	top: "act23"
	name: "conv24_relu"
	type: "ReLU"
}

layer {
	bottom: "act23"
	top: "conv24"
	name: "conv24"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv24"
	top: "act24"
	name: "bn_conv25"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv24"
	top: "act24"
	name: "bn_conv25"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale25"
	type: "Scale"
	bottom: "act24"
	top: "act24"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act24"
	top: "act24"
	name: "conv25_relu"
	type: "ReLU"
}

layer {
	bottom: "act24"
	top: "conv25"
	name: "conv25"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}


layer {
	bottom: "res11"
	top: "short_act12"
	name: "bn_short12"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res11"
	top: "short_act12"
	name: "bn_short12"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_short_scale12"
	type: "Scale"
	bottom: "short_act12"
	top: "short_act12"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "short_act12"
	top: "short_act12"
	name: "short12_relu"
	type: "ReLU"
}

layer {
	bottom: "short_act12"
	top: "short_conv12"
	name: "short_conv12"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		pad: 0
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}
layer {
	bottom: "short_conv12"
	bottom: "conv25"
	top: "res12"
	name: "res12"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 13 ---------#####

layer {
	bottom: "res12"
	top: "act25"
	name: "bn_conv26"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res12"
	top: "act25"
	name: "bn_conv26"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale26"
	type: "Scale"
	bottom: "act25"
	top: "act25"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act25"
	top: "act25"
	name: "conv26_relu"
	type: "ReLU"
}

layer {
	bottom: "act25"
	top: "conv26"
	name: "conv26"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv26"
	top: "act26"
	name: "bn_conv27"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv26"
	top: "act26"
	name: "bn_conv27"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale27"
	type: "Scale"
	bottom: "act26"
	top: "act26"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act26"
	top: "act26"
	name: "conv27_relu"
	type: "ReLU"
}

layer {
	bottom: "act26"
	top: "conv27"
	name: "conv27"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}


layer {
	bottom: "res12"
	top: "short_act13"
	name: "bn_short13"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res12"
	top: "short_act13"
	name: "bn_short13"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_short_scale13"
	type: "Scale"
	bottom: "short_act13"
	top: "short_act13"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "short_act13"
	top: "short_act13"
	name: "short13_relu"
	type: "ReLU"
}

layer {
	bottom: "short_act13"
	top: "short_conv13"
	name: "short_conv13"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		pad: 0
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}
layer {
	bottom: "short_conv13"
	bottom: "conv27"
	top: "res13"
	name: "res13"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 14 ---------#####

layer {
	bottom: "res13"
	top: "act27"
	name: "bn_conv28"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res13"
	top: "act27"
	name: "bn_conv28"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale28"
	type: "Scale"
	bottom: "act27"
	top: "act27"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act27"
	top: "act27"
	name: "conv28_relu"
	type: "ReLU"
}

layer {
	bottom: "act27"
	top: "conv28"
	name: "conv28"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv28"
	top: "act28"
	name: "bn_conv29"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv28"
	top: "act28"
	name: "bn_conv29"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale29"
	type: "Scale"
	bottom: "act28"
	top: "act28"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act28"
	top: "act28"
	name: "conv29_relu"
	type: "ReLU"
}

layer {
	bottom: "act28"
	top: "conv29"
	name: "conv29"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}


layer {
	bottom: "res13"
	top: "short_act14"
	name: "bn_short14"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res13"
	top: "short_act14"
	name: "bn_short14"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_short_scale14"
	type: "Scale"
	bottom: "short_act14"
	top: "short_act14"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "short_act14"
	top: "short_act14"
	name: "short14_relu"
	type: "ReLU"
}

layer {
	bottom: "short_act14"
	top: "short_conv14"
	name: "short_conv14"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		pad: 0
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}
layer {
	bottom: "short_conv14"
	bottom: "conv29"
	top: "res14"
	name: "res14"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 15 ---------#####

layer {
	bottom: "res14"
	top: "in_res15"
	name: "conv15_1"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
		weight_filler {
			type: "gaussian"
			std: 0.18
			#std: 0.02
		}
	}
}

layer {
	bottom: "res14"
	top: "act29"
	name: "bn_conv30"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res14"
	top: "act29"
	name: "bn_conv30"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale30"
	type: "Scale"
	bottom: "act29"
	top: "act29"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act29"
	top: "act29"
	name: "conv30_relu"
	type: "ReLU"
}

layer {
	bottom: "act29"
	top: "conv30"
	name: "conv30"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 2
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv30"
	top: "act30"
	name: "bn_conv31"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv30"
	top: "act30"
	name: "bn_conv31"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale31"
	type: "Scale"
	bottom: "act30"
	top: "act30"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act30"
	top: "act30"
	name: "conv31_relu"
	type: "ReLU"
}

layer {
	bottom: "act30"
	top: "conv31"
	name: "conv31"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "in_res15"
	bottom: "conv31"
	top: "res15"
	name: "res15"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 16 ---------#####

layer {
	bottom: "res15"
	top: "act31"
	name: "bn_conv32"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res15"
	top: "act31"
	name: "bn_conv32"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale32"
	type: "Scale"
	bottom: "act31"
	top: "act31"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act31"
	top: "act31"
	name: "conv32_relu"
	type: "ReLU"
}

layer {
	bottom: "act31"
	top: "conv32"
	name: "conv32"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv32"
	top: "act32"
	name: "bn_conv33"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv32"
	top: "act32"
	name: "bn_conv33"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale33"
	type: "Scale"
	bottom: "act32"
	top: "act32"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act32"
	top: "act32"
	name: "conv33_relu"
	type: "ReLU"
}

layer {
	bottom: "act32"
	top: "conv33"
	name: "conv33"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}


layer {
	bottom: "res15"
	top: "short_act16"
	name: "bn_short16"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res15"
	top: "short_act16"
	name: "bn_short16"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_short_scale16"
	type: "Scale"
	bottom: "short_act16"
	top: "short_act16"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "short_act16"
	top: "short_act16"
	name: "short16_relu"
	type: "ReLU"
}

layer {
	bottom: "short_act16"
	top: "short_conv16"
	name: "short_conv16"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "short_conv16"
	bottom: "conv33"
	top: "res16"
	name: "res16"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 17 ---------#####

layer {
	bottom: "res16"
	top: "act33"
	name: "bn_conv34"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res16"
	top: "act33"
	name: "bn_conv34"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale34"
	type: "Scale"
	bottom: "act33"
	top: "act33"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act33"
	top: "act33"
	name: "conv34_relu"
	type: "ReLU"
}

layer {
	bottom: "act33"
	top: "conv34"
	name: "conv34"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv34"
	top: "act34"
	name: "bn_conv35"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv34"
	top: "act34"
	name: "bn_conv35"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale35"
	type: "Scale"
	bottom: "act34"
	top: "act34"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act34"
	top: "act34"
	name: "conv35_relu"
	type: "ReLU"
}

layer {
	bottom: "act34"
	top: "conv35"
	name: "conv35"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res16"
	top: "short_act17"
	name: "bn_short17"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res16"
	top: "short_act17"
	name: "bn_short17"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_short_scale17"
	type: "Scale"
	bottom: "short_act17"
	top: "short_act17"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "short_act17"
	top: "short_act17"
	name: "short17_relu"
	type: "ReLU"
}

layer {
	bottom: "short_act17"
	top: "short_conv17"
	name: "short_conv17"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "short_conv17"
	bottom: "conv35"
	top: "res17"
	name: "res17"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 18 ---------#####

layer {
	bottom: "res17"
	top: "act35"
	name: "bn_conv36"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res17"
	top: "act35"
	name: "bn_conv36"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale36"
	type: "Scale"
	bottom: "act35"
	top: "act35"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act35"
	top: "act35"
	name: "conv36_relu"
	type: "ReLU"
}

layer {
	bottom: "act35"
	top: "conv36"
	name: "conv36"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv36"
	top: "act36"
	name: "bn_conv37"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv36"
	top: "act36"
	name: "bn_conv37"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale37"
	type: "Scale"
	bottom: "act36"
	top: "act36"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act36"
	top: "act36"
	name: "conv37_relu"
	type: "ReLU"
}

layer {
	bottom: "act36"
	top: "conv37"
	name: "conv37"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res17"
	top: "short_act18"
	name: "bn_short18"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res17"
	top: "short_act18"
	name: "bn_short18"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_short_scale18"
	type: "Scale"
	bottom: "short_act18"
	top: "short_act18"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "short_act18"
	top: "short_act18"
	name: "short18_relu"
	type: "ReLU"
}

layer {
	bottom: "short_act18"
	top: "short_conv18"
	name: "short_conv18"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "short_conv18"
	bottom: "conv37"
	top: "res18"
	name: "res18"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 19 ---------#####

layer {
	bottom: "res18"
	top: "conv38"
	name: "conv38"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv38"
	top: "conv38"
	name: "bn_conv38"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv38"
	top: "conv38"
	name: "bn_conv38"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "conv38"
	top: "conv38"
	name: "conv38_relu"
	type: "ReLU"
}

layer {
	bottom: "conv38"
	top: "conv39"
	name: "conv39"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res18"
	bottom: "conv39"
	top: "res19"
	name: "res19"
	type: "Eltwise"
}

layer {
	bottom: "res19"
	top: "res19"
	name: "bn_res19"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res19"
	top: "res19"
	name: "bn_res19"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom:"res19"
	top: "res19"
	name: "res19_relu"
	type: "ReLU"
}

####----    ----####

#####------- Residual Block 20 ---------#####

layer {
	bottom: "res19"
	top: "act39"
	name: "bn_conv40"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res19"
	top: "act39"
	name: "bn_conv40"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale40"
	type: "Scale"
	bottom: "act39"
	top: "act39"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act39"
	top: "act39"
	name: "conv40_relu"
	type: "ReLU"
}

layer {
	bottom: "act39"
	top: "conv40"
	name: "conv40"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv40"
	top: "act40"
	name: "bn_conv41"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv40"
	top: "act40"
	name: "bn_conv41"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale41"
	type: "Scale"
	bottom: "act40"
	top: "act40"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act40"
	top: "act40"
	name: "conv41_relu"
	type: "ReLU"
}

layer {
	bottom: "act40"
	top: "conv41"
	name: "conv41"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res19"
	top: "short_act20"
	name: "bn_short20"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res19"
	top: "short_act20"
	name: "bn_short20"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_short_scale20"
	type: "Scale"
	bottom: "short_act20"
	top: "short_act20"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "short_act20"
	top: "short_act20"
	name: "short20_relu"
	type: "ReLU"
}

layer {
	bottom: "short_act20"
	top: "short_conv20"
	name: "short_conv20"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "short_conv20"
	bottom: "conv41"
	top: "res20"
	name: "res20"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 21 ---------#####

layer {
	bottom: "res20"
	top: "act41"
	name: "bn_conv42"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res20"
	top: "act41"
	name: "bn_conv42"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale42"
	type: "Scale"
	bottom: "act41"
	top: "act41"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act41"
	top: "act41"
	name: "conv42_relu"
	type: "ReLU"
}

layer {
	bottom: "act41"
	top: "conv42"
	name: "conv42"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv42"
	top: "act42"
	name: "bn_conv43"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv42"
	top: "act42"
	name: "bn_conv43"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale43"
	type: "Scale"
	bottom: "act42"
	top: "act42"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act42"
	top: "act42"
	name: "conv43_relu"
	type: "ReLU"
}

layer {
	bottom: "act42"
	top: "conv43"
	name: "conv43"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res20"
	top: "short_act21"
	name: "bn_short21"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res20"
	top: "short_act21"
	name: "bn_short21"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_short_scale21"
	type: "Scale"
	bottom: "short_act21"
	top: "short_act21"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "short_act21"
	top: "short_act21"
	name: "short21_relu"
	type: "ReLU"
}

layer {
	bottom: "short_act21"
	top: "short_conv21"
	name: "short_conv21"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "short_conv21"
	bottom: "conv43"
	top: "res21"
	name: "res21"
	type: "Eltwise"
}

####----    ----####

# Block 22 -#

layer {
	bottom: "res21"
	top: "act43"
	name: "bn_conv44"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res21"
	top: "act43"
	name: "bn_conv44"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale44"
	type: "Scale"
	bottom: "act43"
	top: "act43"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act43"
	top: "act43"
	name: "conv44_relu"
	type: "ReLU"
}

layer {
	bottom: "act43"
	top: "avg_pool"
	name: "avg_pool"
	type: "Pooling"
	pooling_param {
		pool: AVE
		global_pooling: true
	}
}

layer {
	bottom:"avg_pool"
	top: "fc10"
	name: "fc10"
	type: "InnerProduct"
	inner_product_param {
		num_output: 10
		weight_filler {
			type: "gaussian"
			std: 0.1
		}
		bias_filler {
			type: "constant"
		}
	}
}


layer {
	name: "accuracy"
	type: "Accuracy"
	bottom: "fc10"
	bottom: "label"
	top: "accuracy"
}

layer {
	name: "loss"
	type: "SoftmaxWithLoss"
	bottom: "fc10"
	bottom: "label"
	top: "loss"
}
