name: "ResNet-44"
layer {
	name: "cifar"
	type: "Data"
	top: "data"
	top: "label"
	include {
		phase: TRAIN
	}
	transform_param {
		mean_file: "examples/cifar10/mean.binaryproto"
		mirror: 1
		crop_size: 28
	}
	data_param {
		source: "examples/cifar10/cifar10_train_lmdb"
		batch_size: 80
		backend: LMDB
	}
}
layer {
	name: "cifar"
	type: "Data"
	top: "data"
	top: "label"
	include {
		phase : TEST
	}
	transform_param {
		mean_file: "examples/cifar10/mean.binaryproto"
	}
	data_param {
		source: "examples/cifar10/cifar10_test_lmdb"
		batch_size: 1
		backend: LMDB
	}
}

layer {
	bottom: "data"
	top: "conv1"
	name: "conv1"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 4
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv1"
	top: "conv1"
	name: "bn_conv1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv1"
	top: "conv1"
	name: "bn_conv1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale1"
	type: "Scale"
	bottom: "conv1"
	top: "conv1"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "conv1"
	top: "conv1"
	name: "conv1_relu"
	type: "ReLU"
}

#####------- Residual Block 1 ---------#####

layer {
	bottom: "conv1"
	top: "act1"
	name: "bn_conv2"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv1"
	top: "act1"
	name: "bn_conv2"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale2"
	type: "Scale"
	bottom: "act1"
	top: "act1"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act1"
	top: "act1"
	name: "conv2_relu"
	type: "ReLU"
}

layer {
	bottom: "act1"
	top: "conv2"
	name: "conv2"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv2"
	top: "act2"
	name: "bn_conv3"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv2"
	top: "act2"
	name: "bn_conv3"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale3"
	type: "Scale"
	bottom: "act2"
	top: "act2"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act2"
	top: "act2"
	name: "conv3_relu"
	type: "ReLU"
}

layer {
	bottom: "act2"
	top: "conv3"
	name: "conv3"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		#bias_filler {
		#	type: "constant"
		#	value: 0.2
		#}
	}
}

layer {
	bottom: "conv1"
	top: "short_act1"
	name: "bn_short1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv1"
	top: "short_act1"
	name: "bn_short1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_short_scale1"
	type: "Scale"
	bottom: "short_act1"
	top: "short_act1"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "short_act1"
	top: "short_act1"
	name: "short1_relu"
	type: "ReLU"
}

layer {
	bottom: "short_act1"
	top: "short_conv1"
	name: "short_conv1"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		pad: 0
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "short_conv1"
	bottom: "conv3"
	top: "res1"
	name: "res1"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 2 ---------#####

layer {
	bottom: "res1"
	top: "act3"
	name: "bn_conv4"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res1"
	top: "act3"
	name: "bn_conv4"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale4"
	type: "Scale"
	bottom: "act3"
	top: "act3"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act3"
	top: "act3"
	name: "conv4_relu"
	type: "ReLU"
}

layer {
	bottom: "act3"
	top: "conv4"
	name: "conv4"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv4"
	top: "act4"
	name: "bn_conv5"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv4"
	top: "act4"
	name: "bn_conv5"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale5"
	type: "Scale"
	bottom: "act4"
	top: "act4"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act4"
	top: "act4"
	name: "conv5_relu"
	type: "ReLU"
}

layer {
	bottom: "act4"
	top: "conv5"
	name: "conv5"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res1"
	top: "short_act2"
	name: "bn_short2"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res1"
	top: "short_act2"
	name: "bn_short2"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_short_scale2"
	type: "Scale"
	bottom: "short_act2"
	top: "short_act2"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "short_act2"
	top: "short_act2"
	name: "short2_relu"
	type: "ReLU"
}

layer {
	bottom: "short_act2"
	top: "short_conv2"
	name: "short_conv2"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		pad: 0
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "short_conv2"
	bottom: "conv5"
	top: "res2"
	name: "res2"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 3 ---------#####

layer {
	bottom: "res2"
	top: "act5"
	name: "bn_conv6"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res2"
	top: "act5"
	name: "bn_conv6"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale6"
	type: "Scale"
	bottom: "act5"
	top: "act5"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act5"
	top: "act5"
	name: "conv6_relu"
	type: "ReLU"
}

layer {
	bottom: "act5"
	top: "conv6"
	name: "conv6"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv6"
	top: "act6"
	name: "bn_conv7"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv6"
	top: "act6"
	name: "bn_conv7"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale7"
	type: "Scale"
	bottom: "act6"
	top: "act6"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act6"
	top: "act6"
	name: "conv7_relu"
	type: "ReLU"
}

layer {
	bottom: "act6"
	top: "conv7"
	name: "conv7"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res2"
	top: "short_act3"
	name: "bn_short3"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res2"
	top: "short_act3"
	name: "bn_short3"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_short_scale3"
	type: "Scale"
	bottom: "short_act3"
	top: "short_act3"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "short_act3"
	top: "short_act3"
	name: "short3_relu"
	type: "ReLU"
}

layer {
	bottom: "short_act3"
	top: "short_conv3"
	name: "short_conv3"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		pad: 0
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "short_conv3"
	bottom: "conv7"
	top: "res3"
	name: "res3"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 4 ---------#####

layer {
	bottom: "res3"
	top: "act7"
	name: "bn_conv8"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res3"
	top: "act7"
	name: "bn_conv8"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale8"
	type: "Scale"
	bottom: "act7"
	top: "act7"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act7"
	top: "act7"
	name: "conv8_relu"
	type: "ReLU"
}

layer {
	bottom: "act7"
	top: "conv8"
	name: "conv8"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv8"
	top: "act8"
	name: "bn_conv9"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv8"
	top: "act8"
	name: "bn_conv9"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale9"
	type: "Scale"
	bottom: "act8"
	top: "act8"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act8"
	top: "act8"
	name: "conv9_relu"
	type: "ReLU"
}

layer {
	bottom: "act8"
	top: "conv9"
	name: "conv9"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res3"
	top: "short_act4"
	name: "bn_short4"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res3"
	top: "short_act4"
	name: "bn_short4"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_short_scale4"
	type: "Scale"
	bottom: "short_act4"
	top: "short_act4"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "short_act4"
	top: "short_act4"
	name: "short4_relu"
	type: "ReLU"
}

layer {
	bottom: "short_act4"
	top: "short_conv4"
	name: "short_conv4"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		pad: 0
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "short_conv4"
	bottom: "conv9"
	top: "res4"
	name: "res4"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 5 ---------#####

layer {
	bottom: "res4"
	top: "act9"
	name: "bn_conv10"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res4"
	top: "act9"
	name: "bn_conv10"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale10"
	type: "Scale"
	bottom: "act9"
	top: "act9"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act9"
	top: "act9"
	name: "conv10_relu"
	type: "ReLU"
}

layer {
	bottom: "act9"
	top: "conv10"
	name: "conv10"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv10"
	top: "act10"
	name: "bn_conv11"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv10"
	top: "act10"
	name: "bn_conv11"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale11"
	type: "Scale"
	bottom: "act10"
	top: "act10"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act10"
	top: "act10"
	name: "conv11_relu"
	type: "ReLU"
}

layer {
	bottom: "act10"
	top: "conv11"
	name: "conv11"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res4"
	top: "short_act5"
	name: "bn_short5"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res4"
	top: "short_act5"
	name: "bn_short5"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_short_scale5"
	type: "Scale"
	bottom: "short_act5"
	top: "short_act5"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "short_act5"
	top: "short_act5"
	name: "short5_relu"
	type: "ReLU"
}

layer {
	bottom: "short_act5"
	top: "short_conv5"
	name: "short_conv5"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		pad: 0
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "short_conv5"
	bottom: "conv11"
	top: "res5"
	name: "res5"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 6 ---------#####

layer {
	bottom: "res5"
	top: "conv12"
	name: "conv12"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv12"
	top: "conv12"
	name: "bn_conv12"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv12"
	top: "conv12"
	name: "bn_conv12"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "conv12"
	top: "conv12"
	name: "conv12_relu"
	type: "ReLU"
}

layer {
	bottom: "conv12"
	top: "conv13"
	name: "conv13"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res5"
	bottom: "conv13"
	top: "res6"
	name: "res6"
	type: "Eltwise"
}

layer {
	bottom: "res6"
	top: "res6"
	name: "bn_res6"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res6"
	top: "res6"
	name: "bn_res6"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "res6"
	top: "res6"
	name: "res6_relu"
	type: "ReLU"
}

####----    ----####

#####------- Residual Inception Block 7 ---------#####

layer {
	bottom: "res6"
	top: "act13"
	name: "bn_conv14"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res6"
	top: "act13"
	name: "bn_conv14"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale14"
	type: "Scale"
	bottom: "act13"
	top: "act13"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act13"
	top: "act13"
	name: "conv14_relu"
	type: "ReLU"
}

layer {
	bottom: "act13"
	top: "inception7_conv1x1"
	name: "inception7_conv1x1"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 8
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception7_conv1x1"
	top: "inception7_conv1x1"
	name: "inception7_conv1x1_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act13"
	top: "inception7_3x3_reduce"
	name: "inception7_3x3_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 8
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception7_3x3_reduce"
	top: "inception7_3x3_reduce"
	name: "inception7_3x3_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act13"
	top: "inception7_5x5_reduce"
	name: "inception7_5x5_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		pad: 2
		stride: 1
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception7_5x5_reduce"
	top: "inception7_5x5_reduce"
	name: "inception7_5x5_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act13"
	top: "inception7_pool"
	type: "Pooling"
	name: "inception7_pool"
	pooling_param {
		pool: MAX
		kernel_size: 3
		stride:1
		pad: 1
	}
}

layer {
	bottom: "inception7_3x3_reduce"
	top: "inception7_3x3"
	name: "inception7_3x3"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception7_3x3"
	top: "inception7_3x3"
	name: "inception7_3x3_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception7_5x5_reduce"
	top: "inception7_5x5"
	name: "inception7_5x5"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 5
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception7_5x5"
	top: "inception7_5x5"
	name: "inception7_5x5_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception7_pool"
	top: "inception7_pool_proj"
	name: "inception7_pool_proj"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 8
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception7_pool_proj"
	top: "inception7_pool_proj"
	name: "inception7_pool_proj_ReLU"
	type: "ReLU"
}

layer {
  name: "inception7_output"
  type: "Concat"
  bottom: "inception7_conv1x1"
  bottom: "inception7_3x3"
  bottom: "inception7_5x5"
  bottom: "inception7_pool_proj"
  top: "inception7_output"
}

layer {
	bottom: "inception7_output"
	top: "res7_inc_output"
	name: "res7_inc_output"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		pad: 0
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		#bias_filler {
		#	type: "constant"
		#	value: 0.2
		#}
	}
}

layer {
	bottom: "res6"
	bottom: "res7_inc_output"
	top: "res7"
	name: "res7"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Inception Block 8 ---------#####

layer {
	bottom: "res7"
	top: "in_res8"
	name: "conv16_1"
	type: "Convolution"
	convolution_param {
		num_output: 32
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
		weight_filler {
			type: "gaussian"
			std: 0.25
			#std:0.02
		}
	}
}

layer {
	bottom: "res7"
	top: "act15"
	name: "bn_conv16"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res7"
	top: "act15"
	name: "bn_conv16"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale16"
	type: "Scale"
	bottom: "act15"
	top: "act15"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act15"
	top: "act15"
	name: "conv16_relu"
	type: "ReLU"
}

layer {
	bottom: "act15"
	top: "inception8_conv1x1"
	name: "inception8_conv1x1"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		stride: 2
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception8_conv1x1"
	top: "inception8_conv1x1"
	name: "inception8_conv1x1_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act15"
	top: "inception8_3x3_reduce"
	name: "inception8_3x3_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		stride: 2
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception8_3x3_reduce"
	top: "inception8_3x3_reduce"
	name: "inception8_3x3_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act15"
	top: "inception8_5x5_reduce"
	name: "inception8_5x5_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		pad: 2
		stride: 2
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception8_5x5_reduce"
	top: "inception8_5x5_reduce"
	name: "inception8_5x5_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act15"
	top: "inception8_pool"
	type: "Pooling"
	name: "inception8_pool"
	pooling_param {
		pool: MAX
		kernel_size: 3
		stride:2
		pad: 0
	}
}

layer {
	bottom: "inception8_3x3_reduce"
	top: "inception8_3x3"
	name: "inception8_3x3"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception8_3x3"
	top: "inception8_3x3"
	name: "inception8_3x3_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception8_5x5_reduce"
	top: "inception8_5x5"
	name: "inception8_5x5"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		kernel_size: 5
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception8_5x5"
	top: "inception8_5x5"
	name: "inception8_5x5_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception8_pool"
	top: "inception8_pool_proj"
	name: "inception8_pool_proj"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception8_pool_proj"
	top: "inception8_pool_proj"
	name: "inception8_pool_proj_ReLU"
	type: "ReLU"
}

layer {
  name: "inception8_output"
  type: "Concat"
  bottom: "inception8_conv1x1"
  bottom: "inception8_3x3"
  bottom: "inception8_5x5"
  bottom: "inception8_pool_proj"
  top: "inception8_output"
}

layer {
	bottom: "inception8_output"
	top: "res8_inc_output"
	name: "res8_inc_output"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		pad: 0
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		#bias_filler {
		#	type: "constant"
		#	value: 0.2
		#}
	}
}

layer {
	bottom: "in_res8"
	bottom: "res8_inc_output"
	top: "res8"
	name: "res8"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Inception Block 9 ---------#####

layer {
	bottom: "res8"
	top: "act17"
	name: "bn_conv18"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res8"
	top: "act17"
	name: "bn_conv18"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale18"
	type: "Scale"
	bottom: "act17"
	top: "act17"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act17"
	top: "act17"
	name: "conv18_relu"
	type: "ReLU"
}

layer {
	bottom: "act17"
	top: "inception9_conv1x1"
	name: "inception9_conv1x1"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception9_conv1x1"
	top: "inception9_conv1x1"
	name: "inception9_conv1x1_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act17"
	top: "inception9_3x3_reduce"
	name: "inception9_3x3_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception9_3x3_reduce"
	top: "inception9_3x3_reduce"
	name: "inception9_3x3_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act17"
	top: "inception9_5x5_reduce"
	name: "inception9_5x5_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		pad: 2
		stride: 1
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception9_5x5_reduce"
	top: "inception9_5x5_reduce"
	name: "inception9_5x5_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act17"
	top: "inception9_pool"
	type: "Pooling"
	name: "inception9_pool"
	pooling_param {
		pool: MAX
		kernel_size: 3
		stride:1
		pad: 1
	}
}

layer {
	bottom: "inception9_3x3_reduce"
	top: "inception9_3x3"
	name: "inception9_3x3"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception9_3x3"
	top: "inception9_3x3"
	name: "inception9_3x3_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception9_5x5_reduce"
	top: "inception9_5x5"
	name: "inception9_5x5"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		kernel_size: 5
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception9_5x5"
	top: "inception9_5x5"
	name: "inception9_5x5_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception9_pool"
	top: "inception9_pool_proj"
	name: "inception9_pool_proj"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception9_pool_proj"
	top: "inception9_pool_proj"
	name: "inception9_pool_proj_ReLU"
	type: "ReLU"
}

layer {
  name: "inception9_output"
  type: "Concat"
  bottom: "inception9_conv1x1"
  bottom: "inception9_3x3"
  bottom: "inception9_5x5"
  bottom: "inception9_pool_proj"
  top: "inception9_output"
}

layer {
	bottom: "inception9_output"
	top: "res9_inc_output"
	name: "res9_inc_output"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		pad: 0
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		#bias_filler {
		#	type: "constant"
		#	value: 0.2
		#}
	}
}

layer {
	bottom: "res8"
	bottom: "res9_inc_output"
	top: "res9"
	name: "res9"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 10 ---------#####

layer {
	bottom: "res9"
	top: "act19"
	name: "bn_conv20"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res9"
	top: "act19"
	name: "bn_conv20"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale20"
	type: "Scale"
	bottom: "act19"
	top: "act19"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act19"
	top: "act19"
	name: "conv20_relu"
	type: "ReLU"
}

layer {
	bottom: "act19"
	top: "conv20"
	name: "conv20"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv20"
	top: "act20"
	name: "bn_conv21"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv20"
	top: "act20"
	name: "bn_conv21"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale21"
	type: "Scale"
	bottom: "act20"
	top: "act20"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act20"
	top: "act20"
	name: "conv21_relu"
	type: "ReLU"
}

layer {
	bottom: "act20"
	top: "conv21"
	name: "conv21"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res9"
	bottom: "conv21"
	top: "res10"
	name: "res10"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Inception Block 11 ---------#####

layer {
	bottom: "res10"
	top: "act21"
	name: "bn_conv22"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res10"
	top: "act21"
	name: "bn_conv22"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale22"
	type: "Scale"
	bottom: "act21"
	top: "act21"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act21"
	top: "act21"
	name: "conv22_relu"
	type: "ReLU"
}

layer {
	bottom: "act21"
	top: "inception11_conv1x1"
	name: "inception11_conv1x1"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception11_conv1x1"
	top: "inception11_conv1x1"
	name: "inception11_conv1x1_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act21"
	top: "inception11_3x3_reduce"
	name: "inception11_3x3_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception11_3x3_reduce"
	top: "inception11_3x3_reduce"
	name: "inception11_3x3_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act21"
	top: "inception11_5x5_reduce"
	name: "inception11_5x5_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		pad: 2
		stride: 1
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception11_5x5_reduce"
	top: "inception11_5x5_reduce"
	name: "inception11_5x5_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act21"
	top: "inception11_pool"
	type: "Pooling"
	name: "inception11_pool"
	pooling_param {
		pool: MAX
		kernel_size: 3
		stride:1
		pad: 1
	}
}

layer {
	bottom: "inception11_3x3_reduce"
	top: "inception11_3x3"
	name: "inception11_3x3"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception11_3x3"
	top: "inception11_3x3"
	name: "inception11_3x3_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception11_5x5_reduce"
	top: "inception11_5x5"
	name: "inception11_5x5"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		kernel_size: 5
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception11_5x5"
	top: "inception11_5x5"
	name: "inception11_5x5_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception11_pool"
	top: "inception11_pool_proj"
	name: "inception11_pool_proj"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception11_pool_proj"
	top: "inception11_pool_proj"
	name: "inception11_pool_proj_ReLU"
	type: "ReLU"
}

layer {
  name: "inception11_output"
  type: "Concat"
  bottom: "inception11_conv1x1"
  bottom: "inception11_3x3"
  bottom: "inception11_5x5"
  bottom: "inception11_pool_proj"
  top: "inception11_output"
}

layer {
	bottom: "inception11_output"
	top: "res11_inc_output"
	name: "res11_inc_output"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		pad: 0
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		#bias_filler {
		#	type: "constant"
		#	value: 0.2
		#}
	}
}

layer {
	bottom: "res10"
	bottom: "res11_inc_output"
	top: "res11"
	name: "res11"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Inception Block 12 ---------#####

layer {
	bottom: "res11"
	top: "act23"
	name: "bn_conv24"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res11"
	top: "act23"
	name: "bn_conv24"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale24"
	type: "Scale"
	bottom: "act23"
	top: "act23"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act23"
	top: "act23"
	name: "conv24_relu"
	type: "ReLU"
}

layer {
	bottom: "act23"
	top: "inception12_conv1x1"
	name: "inception12_conv1x1"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception12_conv1x1"
	top: "inception12_conv1x1"
	name: "inception12_conv1x1_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act23"
	top: "inception12_3x3_reduce"
	name: "inception12_3x3_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception12_3x3_reduce"
	top: "inception12_3x3_reduce"
	name: "inception12_3x3_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act23"
	top: "inception12_5x5_reduce"
	name: "inception12_5x5_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		pad: 2
		stride: 1
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception12_5x5_reduce"
	top: "inception12_5x5_reduce"
	name: "inception12_5x5_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act23"
	top: "inception12_pool"
	type: "Pooling"
	name: "inception12_pool"
	pooling_param {
		pool: MAX
		kernel_size: 3
		stride:1
		pad: 1
	}
}

layer {
	bottom: "inception12_3x3_reduce"
	top: "inception12_3x3"
	name: "inception12_3x3"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception12_3x3"
	top: "inception12_3x3"
	name: "inception12_3x3_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception12_5x5_reduce"
	top: "inception12_5x5"
	name: "inception12_5x5"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		kernel_size: 5
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception12_5x5"
	top: "inception12_5x5"
	name: "inception12_5x5_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception12_pool"
	top: "inception12_pool_proj"
	name: "inception12_pool_proj"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception12_pool_proj"
	top: "inception12_pool_proj"
	name: "inception12_pool_proj_ReLU"
	type: "ReLU"
}

layer {
  name: "inception12_output"
  type: "Concat"
  bottom: "inception12_conv1x1"
  bottom: "inception12_3x3"
  bottom: "inception12_5x5"
  bottom: "inception12_pool_proj"
  top: "inception12_output"
}

layer {
	bottom: "inception12_output"
	top: "res12_inc_output"
	name: "res12_inc_output"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		pad: 0
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		#bias_filler {
		#	type: "constant"
		#	value: 0.2
		#}
	}
}

layer {
	bottom: "res11"
	bottom: "res12_inc_output"
	top: "res12"
	name: "res12"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Inception Block 13 ---------#####

layer {
	bottom: "res12"
	top: "act25"
	name: "bn_conv26"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res12"
	top: "act25"
	name: "bn_conv26"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale26"
	type: "Scale"
	bottom: "act25"
	top: "act25"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act25"
	top: "act25"
	name: "conv26_relu"
	type: "ReLU"
}

layer {
	bottom: "act25"
	top: "inception13_conv1x1"
	name: "inception13_conv1x1"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception13_conv1x1"
	top: "inception13_conv1x1"
	name: "inception13_conv1x1_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act25"
	top: "inception13_3x3_reduce"
	name: "inception13_3x3_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception13_3x3_reduce"
	top: "inception13_3x3_reduce"
	name: "inception13_3x3_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act25"
	top: "inception13_5x5_reduce"
	name: "inception13_5x5_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		pad: 2
		stride: 1
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception13_5x5_reduce"
	top: "inception13_5x5_reduce"
	name: "inception13_5x5_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act25"
	top: "inception13_pool"
	type: "Pooling"
	name: "inception13_pool"
	pooling_param {
		pool: MAX
		kernel_size: 3
		stride:1
		pad: 1
	}
}

layer {
	bottom: "inception13_3x3_reduce"
	top: "inception13_3x3"
	name: "inception13_3x3"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception13_3x3"
	top: "inception13_3x3"
	name: "inception13_3x3_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception13_5x5_reduce"
	top: "inception13_5x5"
	name: "inception13_5x5"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		kernel_size: 5
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception13_5x5"
	top: "inception13_5x5"
	name: "inception13_5x5_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception13_pool"
	top: "inception13_pool_proj"
	name: "inception13_pool_proj"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception13_pool_proj"
	top: "inception13_pool_proj"
	name: "inception13_pool_proj_ReLU"
	type: "ReLU"
}

layer {
  name: "inception13_output"
  type: "Concat"
  bottom: "inception13_conv1x1"
  bottom: "inception13_3x3"
  bottom: "inception13_5x5"
  bottom: "inception13_pool_proj"
  top: "inception13_output"
}

layer {
	bottom: "inception13_output"
	top: "res13_inc_output"
	name: "res13_inc_output"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		pad: 0
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		#bias_filler {
		#	type: "constant"
		#	value: 0.2
		#}
	}
}

layer {
	bottom: "res12"
	bottom: "res13_inc_output"
	top: "res13"
	name: "res13"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Inception Block 14 ---------#####

layer {
	bottom: "res13"
	top: "act27"
	name: "bn_conv28"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res13"
	top: "act27"
	name: "bn_conv28"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale28"
	type: "Scale"
	bottom: "act27"
	top: "act27"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act27"
	top: "act27"
	name: "conv28_relu"
	type: "ReLU"
}

layer {
	bottom: "act27"
	top: "inception14_conv1x1"
	name: "inception14_conv1x1"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception14_conv1x1"
	top: "inception14_conv1x1"
	name: "inception14_conv1x1_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act27"
	top: "inception14_3x3_reduce"
	name: "inception14_3x3_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception14_3x3_reduce"
	top: "inception14_3x3_reduce"
	name: "inception14_3x3_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act27"
	top: "inception14_5x5_reduce"
	name: "inception14_5x5_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		pad: 2
		stride: 1
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception14_5x5_reduce"
	top: "inception14_5x5_reduce"
	name: "inception14_5x5_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act27"
	top: "inception14_pool"
	type: "Pooling"
	name: "inception14_pool"
	pooling_param {
		pool: MAX
		kernel_size: 3
		stride:1
		pad: 1
	}
}

layer {
	bottom: "inception14_3x3_reduce"
	top: "inception14_3x3"
	name: "inception14_3x3"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception14_3x3"
	top: "inception14_3x3"
	name: "inception14_3x3_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception14_5x5_reduce"
	top: "inception14_5x5"
	name: "inception14_5x5"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		kernel_size: 5
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception14_5x5"
	top: "inception14_5x5"
	name: "inception14_5x5_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception14_pool"
	top: "inception14_pool_proj"
	name: "inception14_pool_proj"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception14_pool_proj"
	top: "inception14_pool_proj"
	name: "inception14_pool_proj_ReLU"
	type: "ReLU"
}

layer {
  name: "inception14_output"
  type: "Concat"
  bottom: "inception14_conv1x1"
  bottom: "inception14_3x3"
  bottom: "inception14_5x5"
  bottom: "inception14_pool_proj"
  top: "inception14_output"
}

layer {
	bottom: "inception14_output"
	top: "res14_inc_output"
	name: "res14_inc_output"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		pad: 0
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		#bias_filler {
		#	type: "constant"
		#	value: 0.2
		#}
	}
}

layer {
	bottom: "res13"
	bottom: "res14_inc_output"
	top: "res14"
	name: "res14"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Inception Block 15 ---------#####

layer {
	bottom: "res14"
	top: "in_res15"
	name: "conv30_1"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
		weight_filler {
			type: "gaussian"
			std: 0.18
			#std: 0.02
		}
	}
}

layer {
	bottom: "res14"
	top: "act29"
	name: "bn_conv30"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res14"
	top: "act29"
	name: "bn_conv30"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale30"
	type: "Scale"
	bottom: "act29"
	top: "act29"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act29"
	top: "act29"
	name: "conv30_relu"
	type: "ReLU"
}

layer {
	bottom: "act29"
	top: "inception15_conv1x1"
	name: "inception15_conv1x1"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		stride: 2
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception15_conv1x1"
	top: "inception15_conv1x1"
	name: "inception15_conv1x1_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act29"
	top: "inception15_3x3_reduce"
	name: "inception15_3x3_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		stride: 2
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception15_3x3_reduce"
	top: "inception15_3x3_reduce"
	name: "inception15_3x3_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act29"
	top: "inception15_5x5_reduce"
	name: "inception15_5x5_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		pad: 2
		stride: 2
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception15_5x5_reduce"
	top: "inception15_5x5_reduce"
	name: "inception15_5x5_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act29"
	top: "inception15_pool"
	type: "Pooling"
	name: "inception15_pool"
	pooling_param {
		pool: MAX
		kernel_size: 3
		stride:2
		pad: 1
	}
}

layer {
	bottom: "inception15_3x3_reduce"
	top: "inception15_3x3"
	name: "inception15_3x3"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception15_3x3"
	top: "inception15_3x3"
	name: "inception15_3x3_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception15_5x5_reduce"
	top: "inception15_5x5"
	name: "inception15_5x5"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 128
		kernel_size: 5
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception15_5x5"
	top: "inception15_5x5"
	name: "inception15_5x5_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception15_pool"
	top: "inception15_pool_proj"
	name: "inception15_pool_proj"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception15_pool_proj"
	top: "inception15_pool_proj"
	name: "inception15_pool_proj_ReLU"
	type: "ReLU"
}

layer {
  name: "inception15_output"
  type: "Concat"
  bottom: "inception15_conv1x1"
  bottom: "inception15_3x3"
  bottom: "inception15_5x5"
  bottom: "inception15_pool_proj"
  top: "inception15_output"
}

layer {
	bottom: "inception15_output"
	top: "res15_inc_output"
	name: "res15_inc_output"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		#bias_filler {
		#	type: "constant"
		#	value: 0.2
		#}
	}
}

layer {
	bottom: "in_res15"
	bottom: "res15_inc_output"
	top: "res15"
	name: "res15"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Inception Block 16 ---------#####

layer {
	bottom: "res15"
	top: "act31"
	name: "bn_conv32"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res15"
	top: "act31"
	name: "bn_conv32"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale32"
	type: "Scale"
	bottom: "act31"
	top: "act31"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act31"
	top: "act31"
	name: "conv32_relu"
	type: "ReLU"
}

layer {
	bottom: "act31"
	top: "inception16_conv1x1"
	name: "inception16_conv1x1"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception16_conv1x1"
	top: "inception16_conv1x1"
	name: "inception16_conv1x1_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act31"
	top: "inception16_3x3_reduce"
	name: "inception16_3x3_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception16_3x3_reduce"
	top: "inception16_3x3_reduce"
	name: "inception16_3x3_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act31"
	top: "inception16_5x5_reduce"
	name: "inception16_5x5_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		pad: 2
		stride: 1
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception16_5x5_reduce"
	top: "inception16_5x5_reduce"
	name: "inception16_5x5_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act31"
	top: "inception16_pool"
	type: "Pooling"
	name: "inception16_pool"
	pooling_param {
		pool: MAX
		kernel_size: 3
		stride:1
		pad: 1
	}
}

layer {
	bottom: "inception16_3x3_reduce"
	top: "inception16_3x3"
	name: "inception16_3x3"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception16_3x3"
	top: "inception16_3x3"
	name: "inception16_3x3_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception16_5x5_reduce"
	top: "inception16_5x5"
	name: "inception16_5x5"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 128
		kernel_size: 5
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception16_5x5"
	top: "inception16_5x5"
	name: "inception16_5x5_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception16_pool"
	top: "inception16_pool_proj"
	name: "inception16_pool_proj"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception16_pool_proj"
	top: "inception16_pool_proj"
	name: "inception16_pool_proj_ReLU"
	type: "ReLU"
}

layer {
  name: "inception16_output"
  type: "Concat"
  bottom: "inception16_conv1x1"
  bottom: "inception16_3x3"
  bottom: "inception16_5x5"
  bottom: "inception16_pool_proj"
  top: "inception16_output"
}

layer {
	bottom: "inception16_output"
	top: "res16_inc_output"
	name: "res16_inc_output"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		#bias_filler {
		#	type: "constant"
		#	value: 0.2
		#}
	}
}

layer {
	bottom: "res15"
	bottom: "res16_inc_output"
	top: "res16"
	name: "res16"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 17 ---------#####

layer {
	bottom: "res16"
	top: "act33"
	name: "bn_conv34"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res16"
	top: "act33"
	name: "bn_conv34"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale34"
	type: "Scale"
	bottom: "act33"
	top: "act33"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act33"
	top: "act33"
	name: "conv34_relu"
	type: "ReLU"
}

layer {
	bottom: "act33"
	top: "conv34"
	name: "conv34"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv34"
	top: "act34"
	name: "bn_conv35"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv34"
	top: "act34"
	name: "bn_conv35"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale35"
	type: "Scale"
	bottom: "act34"
	top: "act34"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act34"
	top: "act34"
	name: "conv35_relu"
	type: "ReLU"
}

layer {
	bottom: "act34"
	top: "conv35"
	name: "conv35"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res16"
	top: "short_act17"
	name: "bn_short17"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res16"
	top: "short_act17"
	name: "bn_short17"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_short_scale17"
	type: "Scale"
	bottom: "short_act17"
	top: "short_act17"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "short_act17"
	top: "short_act17"
	name: "short17_relu"
	type: "ReLU"
}

layer {
	bottom: "short_act17"
	top: "short_conv17"
	name: "short_conv17"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "short_conv17"
	bottom: "conv35"
	top: "res17"
	name: "res17"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Inception Block 18 ---------#####

layer {
	bottom: "res17"
	top: "act35"
	name: "bn_conv36"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res17"
	top: "act35"
	name: "bn_conv36"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale36"
	type: "Scale"
	bottom: "act35"
	top: "act35"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act35"
	top: "act35"
	name: "conv36_relu"
	type: "ReLU"
}

layer {
	bottom: "act35"
	top: "inception18_conv1x1"
	name: "inception18_conv1x1"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception18_conv1x1"
	top: "inception18_conv1x1"
	name: "inception18_conv1x1_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act35"
	top: "inception18_3x3_reduce"
	name: "inception18_3x3_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception18_3x3_reduce"
	top: "inception18_3x3_reduce"
	name: "inception18_3x3_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act35"
	top: "inception18_5x5_reduce"
	name: "inception18_5x5_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		pad: 2
		stride: 1
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception18_5x5_reduce"
	top: "inception18_5x5_reduce"
	name: "inception18_5x5_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act35"
	top: "inception18_pool"
	type: "Pooling"
	name: "inception18_pool"
	pooling_param {
		pool: MAX
		kernel_size: 3
		stride:1
		pad: 1
	}
}

layer {
	bottom: "inception18_3x3_reduce"
	top: "inception18_3x3"
	name: "inception18_3x3"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception18_3x3"
	top: "inception18_3x3"
	name: "inception18_3x3_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception18_5x5_reduce"
	top: "inception18_5x5"
	name: "inception18_5x5"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 128
		kernel_size: 5
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception18_5x5"
	top: "inception18_5x5"
	name: "inception18_5x5_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception18_pool"
	top: "inception18_pool_proj"
	name: "inception18_pool_proj"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception18_pool_proj"
	top: "inception18_pool_proj"
	name: "inception18_pool_proj_ReLU"
	type: "ReLU"
}

layer {
  name: "inception18_output"
  type: "Concat"
  bottom: "inception18_conv1x1"
  bottom: "inception18_3x3"
  bottom: "inception18_5x5"
  bottom: "inception18_pool_proj"
  top: "inception18_output"
}

layer {
	bottom: "inception18_output"
	top: "res18_inc_output"
	name: "res18_inc_output"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		#bias_filler {
		#	type: "constant"
		#	value: 0.2
		#}
	}
}

layer {
	bottom: "res17"
	bottom: "res18_inc_output"
	top: "res18"
	name: "res18"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Inception Block 19 ---------#####

layer {
	bottom: "res18"
	top: "act37"
	name: "bn_conv38"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res18"
	top: "act37"
	name: "bn_conv38"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale38"
	type: "Scale"
	bottom: "act37"
	top: "act37"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act37"
	top: "act37"
	name: "conv38_relu"
	type: "ReLU"
}

layer {
	bottom: "act37"
	top: "inception19_conv1x1"
	name: "inception19_conv1x1"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception19_conv1x1"
	top: "inception19_conv1x1"
	name: "inception19_conv1x1_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act37"
	top: "inception19_3x3_reduce"
	name: "inception19_3x3_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception19_3x3_reduce"
	top: "inception19_3x3_reduce"
	name: "inception19_3x3_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act37"
	top: "inception19_5x5_reduce"
	name: "inception19_5x5_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		pad: 2
		stride: 1
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception19_5x5_reduce"
	top: "inception19_5x5_reduce"
	name: "inception19_5x5_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act37"
	top: "inception19_pool"
	type: "Pooling"
	name: "inception19_pool"
	pooling_param {
		pool: MAX
		kernel_size: 3
		stride:1
		pad: 1
	}
}

layer {
	bottom: "inception19_3x3_reduce"
	top: "inception19_3x3"
	name: "inception19_3x3"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception19_3x3"
	top: "inception19_3x3"
	name: "inception19_3x3_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception19_5x5_reduce"
	top: "inception19_5x5"
	name: "inception19_5x5"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 128
		kernel_size: 5
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception19_5x5"
	top: "inception19_5x5"
	name: "inception19_5x5_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception19_pool"
	top: "inception19_pool_proj"
	name: "inception19_pool_proj"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception19_pool_proj"
	top: "inception19_pool_proj"
	name: "inception19_pool_proj_ReLU"
	type: "ReLU"
}

layer {
  name: "inception19_output"
  type: "Concat"
  bottom: "inception19_conv1x1"
  bottom: "inception19_3x3"
  bottom: "inception19_5x5"
  bottom: "inception19_pool_proj"
  top: "inception19_output"
}

layer {
	bottom: "inception19_output"
	top: "res19_inc_output"
	name: "res19_inc_output"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		#bias_filler {
		#	type: "constant"
		#	value: 0.2
		#}
	}
}

layer {
	bottom: "res18"
	bottom: "res19_inc_output"
	top: "res19"
	name: "res19"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Inception Block 20 ---------#####

layer {
	bottom: "res19"
	top: "act39"
	name: "bn_conv40"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res19"
	top: "act39"
	name: "bn_conv40"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale40"
	type: "Scale"
	bottom: "act39"
	top: "act39"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act39"
	top: "act39"
	name: "conv40_relu"
	type: "ReLU"
}

layer {
	bottom: "act39"
	top: "inception20_conv1x1"
	name: "inception20_conv1x1"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception20_conv1x1"
	top: "inception20_conv1x1"
	name: "inception20_conv1x1_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act39"
	top: "inception20_3x3_reduce"
	name: "inception20_3x3_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception20_3x3_reduce"
	top: "inception20_3x3_reduce"
	name: "inception20_3x3_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act39"
	top: "inception20_5x5_reduce"
	name: "inception20_5x5_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		pad: 2
		stride: 1
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception20_5x5_reduce"
	top: "inception20_5x5_reduce"
	name: "inception20_5x5_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act39"
	top: "inception20_pool"
	type: "Pooling"
	name: "inception20_pool"
	pooling_param {
		pool: MAX
		kernel_size: 3
		stride:1
		pad: 1
	}
}

layer {
	bottom: "inception20_3x3_reduce"
	top: "inception20_3x3"
	name: "inception20_3x3"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception20_3x3"
	top: "inception20_3x3"
	name: "inception20_3x3_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception20_5x5_reduce"
	top: "inception20_5x5"
	name: "inception20_5x5"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 128
		kernel_size: 5
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception20_5x5"
	top: "inception20_5x5"
	name: "inception20_5x5_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception20_pool"
	top: "inception20_pool_proj"
	name: "inception20_pool_proj"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception20_pool_proj"
	top: "inception20_pool_proj"
	name: "inception20_pool_proj_ReLU"
	type: "ReLU"
}

layer {
  name: "inception20_output"
  type: "Concat"
  bottom: "inception20_conv1x1"
  bottom: "inception20_3x3"
  bottom: "inception20_5x5"
  bottom: "inception20_pool_proj"
  top: "inception20_output"
}

layer {
	bottom: "inception20_output"
	top: "res20_inc_output"
	name: "res20_inc_output"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		#bias_filler {
		#	type: "constant"
		#	value: 0.2
		#}
	}
}

layer {
	bottom: "res19"
	bottom: "res20_inc_output"
	top: "res20"
	name: "res20"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Inception Block 21 ---------#####

layer {
	bottom: "res20"
	top: "act41"
	name: "bn_conv42"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res20"
	top: "act41"
	name: "bn_conv42"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale42"
	type: "Scale"
	bottom: "act41"
	top: "act41"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act41"
	top: "act41"
	name: "conv42_relu"
	type: "ReLU"
}

layer {
	bottom: "act41"
	top: "inception21_conv1x1"
	name: "inception21_conv1x1"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception21_conv1x1"
	top: "inception21_conv1x1"
	name: "inception21_conv1x1_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act41"
	top: "inception21_3x3_reduce"
	name: "inception21_3x3_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception21_3x3_reduce"
	top: "inception21_3x3_reduce"
	name: "inception21_3x3_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act41"
	top: "inception21_5x5_reduce"
	name: "inception21_5x5_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		pad: 2
		stride: 1
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception21_5x5_reduce"
	top: "inception21_5x5_reduce"
	name: "inception21_5x5_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act41"
	top: "inception21_pool"
	type: "Pooling"
	name: "inception21_pool"
	pooling_param {
		pool: MAX
		kernel_size: 3
		stride:1
		pad: 1
	}
}

layer {
	bottom: "inception21_3x3_reduce"
	top: "inception21_3x3"
	name: "inception21_3x3"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception21_3x3"
	top: "inception21_3x3"
	name: "inception21_3x3_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception21_5x5_reduce"
	top: "inception21_5x5"
	name: "inception21_5x5"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 128
		kernel_size: 5
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception21_5x5"
	top: "inception21_5x5"
	name: "inception21_5x5_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception21_pool"
	top: "inception21_pool_proj"
	name: "inception21_pool_proj"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception21_pool_proj"
	top: "inception21_pool_proj"
	name: "inception21_pool_proj_ReLU"
	type: "ReLU"
}

layer {
  name: "inception21_output"
  type: "Concat"
  bottom: "inception21_conv1x1"
  bottom: "inception21_3x3"
  bottom: "inception21_5x5"
  bottom: "inception21_pool_proj"
  top: "inception21_output"
}

layer {
	bottom: "inception21_output"
	top: "res21_inc_output"
	name: "res21_inc_output"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		#bias_filler {
		#	type: "constant"
		#	value: 0.2
		#}
	}
}

layer {
	bottom: "res20"
	bottom: "res21_inc_output"
	top: "res21"
	name: "res21"
	type: "Eltwise"
}

####----    ----####

# Block 22 -#

layer {
	bottom: "res21"
	top: "act43"
	name: "bn_conv44"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res21"
	top: "act43"
	name: "bn_conv44"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale44"
	type: "Scale"
	bottom: "act43"
	top: "act43"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act43"
	top: "act43"
	name: "conv44_relu"
	type: "ReLU"
}

layer {
	bottom: "act43"
	top: "avg_pool"
	name: "avg_pool"
	type: "Pooling"
	pooling_param {
		pool: AVE
		global_pooling: true
	}
}

layer {
	bottom:"avg_pool"
	top: "fc10"
	name: "fc10"
	type: "InnerProduct"
	inner_product_param {
		num_output: 10
		weight_filler {
			type: "gaussian"
			std: 0.1
		}
		bias_filler {
			type: "constant"
		}
	}
}


layer {
	name: "accuracy"
	type: "Accuracy"
	bottom: "fc10"
	bottom: "label"
	top: "accuracy"
}

layer {
	name: "loss"
	type: "SoftmaxWithLoss"
	bottom: "fc10"
	bottom: "label"
	top: "loss"
}
