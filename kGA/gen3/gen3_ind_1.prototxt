name: "ResNet-44"
layer {
	name: "cifar"
	type: "Data"
	top: "data"
	top: "label"
	include {
		phase: TRAIN
	}
	transform_param {
		mean_file: "examples/cifar10/mean.binaryproto"
		mirror: 1
		crop_size: 28
	}
	data_param {
		source: "examples/cifar10/cifar10_train_lmdb"
		batch_size: 80
		backend: LMDB
	}
}
layer {
	name: "cifar"
	type: "Data"
	top: "data"
	top: "label"
	include {
		phase : TEST
	}
	transform_param {
		mean_file: "examples/cifar10/mean.binaryproto"
	}
	data_param {
		source: "examples/cifar10/cifar10_test_lmdb"
		batch_size: 1
		backend: LMDB
	}
}

layer {
	bottom: "data"
	top: "conv1"
	name: "conv1"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 4
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv1"
	top: "conv1"
	name: "bn_conv1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv1"
	top: "conv1"
	name: "bn_conv1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale1"
	type: "Scale"
	bottom: "conv1"
	top: "conv1"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "conv1"
	top: "conv1"
	name: "conv1_relu"
	type: "ReLU"
}

#####------- Residual Block 1 ---------#####

layer {
	bottom: "conv1"
	top: "conv2"
	name: "conv2"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv2"
	top: "conv2"
	name: "bn_conv2"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv2"
	top: "conv2"
	name: "bn_conv2"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "conv2"
	top: "conv2"
	name: "conv2_relu"
	type: "ReLU"
}

layer {
	bottom: "conv2"
	top: "conv3"
	name: "conv3"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		#bias_filler {
		#	type: "constant"
		#	value: 0.2
		#}
	}
}

layer {
	bottom: "conv1"
	bottom: "conv3"
	top: "res1"
	name: "res1"
	type: "Eltwise"
}

layer {
	bottom: "res1"
	top: "res1"
	name: "bn_res1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res1"
	top: "res1"
	name: "bn_res1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "res1"
	top: "res1"
	name: "res1_relu"
	type: "ReLU"
}

####----    ----####

#####------- Residual Block 2 ---------#####

layer {
	bottom: "res1"
	top: "conv4"
	name: "conv4"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv4"
	top: "conv4"
	name: "bn_conv4"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv4"
	top: "conv4"
	name: "bn_conv4"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "conv4"
	top: "conv4"
	name: "conv4_relu"
	type: "ReLU"
}

layer {
	bottom: "conv4"
	top: "conv5"
	name: "conv5"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res1"
	bottom: "conv5"
	top: "res2"
	name: "res2"
	type: "Eltwise"
}

layer {
	bottom: "res2"
	top: "res2"
	name: "bn_res2"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res2"
	top: "res2"
	name: "bn_res2"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "res2"
	top: "res2"
	name: "res2_relu"
	type: "ReLU"
}

####----    ----####

#####------- Residual Block 3 ---------#####

layer {
	bottom: "res2"
	top: "conv6"
	name: "conv6"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv6"
	top: "conv6"
	name: "bn_conv6"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv6"
	top: "conv6"
	name: "bn_conv6"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "conv6"
	top: "conv6"
	name: "conv6_relu"
	type: "ReLU"
}

layer {
	bottom: "conv6"
	top: "conv7"
	name: "conv7"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res2"
	bottom: "conv7"
	top: "res3"
	name: "res3"
	type: "Eltwise"
}

layer {
	bottom: "res3"
	top: "res3"
	name: "bn_res3"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res3"
	top: "res3"
	name: "bn_res3"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "res3"
	top: "res3"
	name: "res3_relu"
	type: "ReLU"
}

####----    ----####

#####------- Residual Block 4 ---------#####

layer {
	bottom: "res3"
	top: "conv8"
	name: "conv8"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv8"
	top: "conv8"
	name: "bn_conv8"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv8"
	top: "conv8"
	name: "bn_conv8"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "conv8"
	top: "conv8"
	name: "conv8_relu"
	type: "ReLU"
}

layer {
	bottom: "conv8"
	top: "conv9"
	name: "conv9"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res3"
	bottom: "conv9"
	top: "res4"
	name: "res4"
	type: "Eltwise"
}

layer {
	bottom: "res4"
	top: "res4"
	name: "bn_res4"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res4"
	top: "res4"
	name: "bn_res4"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "res4"
	top: "res4"
	name: "res4_relu"
	type: "ReLU"
}

####----    ----####

#####------- Residual Block 5 ---------#####

layer {
	bottom: "res4"
	top: "conv10"
	name: "conv10"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv10"
	top: "conv10"
	name: "bn_conv10"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv10"
	top: "conv10"
	name: "bn_conv10"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "conv10"
	top: "conv10"
	name: "conv10_relu"
	type: "ReLU"
}

layer {
	bottom: "conv10"
	top: "conv11"
	name: "conv11"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res4"
	bottom: "conv11"
	top: "res5"
	name: "res5"
	type: "Eltwise"
}

layer {
	bottom: "res5"
	top: "res5"
	name: "bn_res5"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res5"
	top: "res5"
	name: "bn_res5"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "res5"
	top: "res5"
	name: "res5_relu"
	type: "ReLU"
}

####----    ----####

#####------- Residual Inception Block 6 ---------#####

layer {
	bottom: "res5"
	top: "act11"
	name: "bn_conv12"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res5"
	top: "act11"
	name: "bn_conv12"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale12"
	type: "Scale"
	bottom: "act11"
	top: "act11"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act11"
	top: "act11"
	name: "conv12_relu"
	type: "ReLU"
}

layer {
	bottom: "act11"
	top: "inception6_conv1x1"
	name: "inception6_conv1x1"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception6_conv1x1"
	top: "inception6_conv1x1"
	name: "inception6_conv1x1_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act11"
	top: "inception6_3x3_reduce"
	name: "inception6_3x3_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception6_3x3_reduce"
	top: "inception6_3x3_reduce"
	name: "inception6_3x3_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act11"
	top: "inception6_5x5_reduce"
	name: "inception6_5x5_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 4
		pad: 2
		stride: 1
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception6_5x5_reduce"
	top: "inception6_5x5_reduce"
	name: "inception6_5x5_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act11"
	top: "inception6_pool"
	type: "Pooling"
	name: "inception6_pool"
	pooling_param {
		pool: MAX
		kernel_size: 3
		stride:1
		pad: 1
	}
}

layer {
	bottom: "inception6_3x3_reduce"
	top: "inception6_3x3"
	name: "inception6_3x3"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception6_3x3"
	top: "inception6_3x3"
	name: "inception6_3x3_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception6_5x5_reduce"
	top: "inception6_5x5"
	name: "inception6_5x5"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 8
		kernel_size: 5
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception6_5x5"
	top: "inception6_5x5"
	name: "inception6_5x5_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception6_pool"
	top: "inception6_pool_proj"
	name: "inception6_pool_proj"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 8
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception6_pool_proj"
	top: "inception6_pool_proj"
	name: "inception6_pool_proj_ReLU"
	type: "ReLU"
}

layer {
  name: "inception6_output"
  type: "Concat"
  bottom: "inception6_conv1x1"
  bottom: "inception6_3x3"
  bottom: "inception6_5x5"
  bottom: "inception6_pool_proj"
  top: "inception6_output"
}

layer {
	bottom: "inception6_output"
	top: "res6_inc_output"
	name: "res6_inc_output"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		pad: 0
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		#bias_filler {
		#	type: "constant"
		#	value: 0.2
		#}
	}
}

layer {
	bottom: "res5"
	bottom: "res6_inc_output"
	top: "res6"
	name: "res6"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 7 ---------#####

layer {
	bottom: "res6"
	top: "conv14"
	name: "conv14"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv14"
	top: "conv14"
	name: "bn_conv14"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv14"
	top: "conv14"
	name: "bn_conv14"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "conv14"
	top: "conv14"
	name: "conv14_relu"
	type: "ReLU"
}

layer {
	bottom: "conv14"
	top: "conv15"
	name: "conv15"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 16
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res6"
	bottom: "conv15"
	top: "res7"
	name: "res7"
	type: "Eltwise"
}

layer {
	bottom: "res7"
	top: "res7"
	name: "bn_res7"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res7"
	top: "res7"
	name: "bn_res7"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "res7"
	top: "res7"
	name: "res7_relu"
	type: "ReLU"
}

####----    ----####

#####------- Residual Block 8 ---------#####

layer {
	bottom: "res7"
	top: "in_res8"
	name: "conv8_1"
	type: "Convolution"
	convolution_param {
		num_output: 32
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
		weight_filler {
			type: "gaussian"
			std: 0.25
			#std:0.02
		}
	}
}

layer {
	bottom: "res7"
	top: "conv16"
	name: "conv16"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 2
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv16"
	top: "conv16"
	name: "bn_conv16"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv16"
	top: "conv16"
	name: "bn_conv16"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "conv16"
	top: "conv16"
	name: "conv16_relu"
	type: "ReLU"
}

layer {
	bottom: "conv16"
	top: "conv17"
	name: "conv17"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "in_res8"
	bottom: "conv17"
	top: "res8"
	name: "res8"
	type: "Eltwise"
}

layer {
	bottom: "res8"
	top: "res8"
	name: "bn_res8"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res8"
	top: "res8"
	name: "bn_res8"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "res8"
	top: "res8"
	name: "res8_relu"
	type: "ReLU"
}

####----    ----####

#####------- Residual Block 9 ---------#####

layer {
	bottom: "res8"
	top: "conv18"
	name: "conv18"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv18"
	top: "conv18"
	name: "bn_conv18"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv18"
	top: "conv18"
	name: "bn_conv18"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "conv18"
	top: "conv18"
	name: "conv18_relu"
	type: "ReLU"
}

layer {
	bottom: "conv18"
	top: "conv19"
	name: "conv19"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res8"
	bottom: "conv19"
	top: "res9"
	name: "res9"
	type: "Eltwise"
}

layer {
	bottom: "res9"
	top: "res9"
	name: "bn_res9"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res9"
	top: "res9"
	name: "bn_res9"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "res9"
	top: "res9"
	name: "res9_relu"
	type: "ReLU"
}

####----    ----####

#####------- Residual Block 10 ---------#####

layer {
	bottom: "res9"
	top: "conv20"
	name: "conv20"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv20"
	top: "conv20"
	name: "bn_conv20"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv20"
	top: "conv20"
	name: "bn_conv20"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "conv20"
	top: "conv20"
	name: "conv20_relu"
	type: "ReLU"
}

layer {
	bottom: "conv20"
	top: "conv21"
	name: "conv21"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res9"
	bottom: "conv21"
	top: "res10"
	name: "res10"
	type: "Eltwise"
}

layer {
	bottom: "res10"
	top: "res10"
	name: "bn_res10"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res10"
	top: "res10"
	name: "bn_res10"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "res10"
	top: "res10"
	name: "res10_relu"
	type: "ReLU"
}

####----    ----####

#####------- Residual Inception Block 11 ---------#####

layer {
	bottom: "res10"
	top: "act21"
	name: "bn_conv22"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res10"
	top: "act21"
	name: "bn_conv22"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale22"
	type: "Scale"
	bottom: "act21"
	top: "act21"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act21"
	top: "act21"
	name: "conv22_relu"
	type: "ReLU"
}

layer {
	bottom: "act21"
	top: "inception11_conv1x1"
	name: "inception11_conv1x1"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception11_conv1x1"
	top: "inception11_conv1x1"
	name: "inception11_conv1x1_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act21"
	top: "inception11_3x3_reduce"
	name: "inception11_3x3_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception11_3x3_reduce"
	top: "inception11_3x3_reduce"
	name: "inception11_3x3_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act21"
	top: "inception11_5x5_reduce"
	name: "inception11_5x5_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 8
		pad: 2
		stride: 1
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception11_5x5_reduce"
	top: "inception11_5x5_reduce"
	name: "inception11_5x5_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act21"
	top: "inception11_pool"
	type: "Pooling"
	name: "inception11_pool"
	pooling_param {
		pool: MAX
		kernel_size: 3
		stride:1
		pad: 1
	}
}

layer {
	bottom: "inception11_3x3_reduce"
	top: "inception11_3x3"
	name: "inception11_3x3"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception11_3x3"
	top: "inception11_3x3"
	name: "inception11_3x3_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception11_5x5_reduce"
	top: "inception11_5x5"
	name: "inception11_5x5"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		kernel_size: 5
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception11_5x5"
	top: "inception11_5x5"
	name: "inception11_5x5_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception11_pool"
	top: "inception11_pool_proj"
	name: "inception11_pool_proj"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception11_pool_proj"
	top: "inception11_pool_proj"
	name: "inception11_pool_proj_ReLU"
	type: "ReLU"
}

layer {
  name: "inception11_output"
  type: "Concat"
  bottom: "inception11_conv1x1"
  bottom: "inception11_3x3"
  bottom: "inception11_5x5"
  bottom: "inception11_pool_proj"
  top: "inception11_output"
}

layer {
	bottom: "inception11_output"
	top: "res11_inc_output"
	name: "res11_inc_output"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		pad: 0
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		#bias_filler {
		#	type: "constant"
		#	value: 0.2
		#}
	}
}

layer {
	bottom: "res10"
	bottom: "res11_inc_output"
	top: "res11"
	name: "res11"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 12 ---------#####

layer {
	bottom: "res11"
	top: "conv24"
	name: "conv24"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv24"
	top: "conv24"
	name: "bn_conv24"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv24"
	top: "conv24"
	name: "bn_conv24"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "conv24"
	top: "conv24"
	name: "conv24_relu"
	type: "ReLU"
}

layer {
	bottom: "conv24"
	top: "conv25"
	name: "conv25"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res11"
	bottom: "conv25"
	top: "res12"
	name: "res12"
	type: "Eltwise"
}

layer {
	bottom: "res12"
	top: "res12"
	name: "bn_res12"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res12"
	top: "res12"
	name: "bn_res12"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "res12"
	top: "res12"
	name: "res12_relu"
	type: "ReLU"
}

####----    ----####

#####------- Residual Block 13 ---------#####

layer {
	bottom: "res12"
	top: "conv26"
	name: "conv26"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv26"
	top: "conv26"
	name: "bn_conv26"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv26"
	top: "conv26"
	name: "bn_conv26"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "conv26"
	top: "conv26"
	name: "conv26_relu"
	type: "ReLU"
}

layer {
	bottom: "conv26"
	top: "conv27"
	name: "conv27"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res12"
	bottom: "conv27"
	top: "res13"
	name: "res13"
	type: "Eltwise"
}

layer {
	bottom: "res13"
	top: "res13"
	name: "bn_res13"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res13"
	top: "res13"
	name: "bn_res13"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "res13"
	top: "res13"
	name: "res13_relu"
	type: "ReLU"
}

####----    ----####

#####------- Residual Block 14 ---------#####

layer {
	bottom: "res13"
	top: "conv28"
	name: "conv28"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv28"
	top: "conv28"
	name: "bn_conv28"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv28"
	top: "conv28"
	name: "bn_conv28"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "conv28"
	top: "conv28"
	name: "conv28_relu"
	type: "ReLU"
}

layer {
	bottom: "conv28"
	top: "conv29"
	name: "conv29"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.08
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res13"
	bottom: "conv29"
	top: "res14"
	name: "res14"
	type: "Eltwise"
}

layer {
	bottom: "res14"
	top: "res14"
	name: "bn_res14"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res14"
	top: "res14"
	name: "bn_res14"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "res14"
	top: "res14"
	name: "res14_relu"
	type: "ReLU"
}

####----    ----####

#####------- Residual Block 15 ---------#####

layer {
	bottom: "res14"
	top: "in_res15"
	name: "conv15_1"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
		weight_filler {
			type: "gaussian"
			std: 0.18
			#std: 0.02
		}
	}
}

layer {
	bottom: "res14"
	top: "conv30"
	name: "conv30"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 2
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv30"
	top: "conv30"
	name: "bn_conv30"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv30"
	top: "conv30"
	name: "bn_conv30"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "conv30"
	top: "conv30"
	name: "conv30_relu"
	type: "ReLU"
}

layer {
	bottom: "conv30"
	top: "conv31"
	name: "conv31"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "in_res15"
	bottom: "conv31"
	top: "res15"
	name: "res15"
	type: "Eltwise"
}

layer {
	bottom: "res15"
	top: "res15"
	name: "bn_res15"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res15"
	top: "res15"
	name: "bn_res15"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "res15"
	top: "res15"
	name: "res15_relu"
	type: "ReLU"
}

####----    ----####

#####------- Residual Block 16 ---------#####

layer {
	bottom: "res15"
	top: "conv32"
	name: "conv32"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv32"
	top: "conv32"
	name: "bn_conv32"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv32"
	top: "conv32"
	name: "bn_conv32"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "conv32"
	top: "conv32"
	name: "conv32_relu"
	type: "ReLU"
}

layer {
	bottom: "conv32"
	top: "conv33"
	name: "conv33"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res15"
	bottom: "conv33"
	top: "res16"
	name: "res16"
	type: "Eltwise"
}

layer {
	bottom: "res16"
	top: "res16"
	name: "bn_res16"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res16"
	top: "res16"
	name: "bn_res16"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "res16"
	top: "res16"
	name: "res16_relu"
	type: "ReLU"
}

####----    ----####

#####------- Residual Block 17 ---------#####

layer {
	bottom: "res16"
	top: "conv34"
	name: "conv34"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv34"
	top: "conv34"
	name: "bn_conv34"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv34"
	top: "conv34"
	name: "bn_conv34"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "conv34"
	top: "conv34"
	name: "conv34_relu"
	type: "ReLU"
}

layer {
	bottom: "conv34"
	top: "conv35"
	name: "conv35"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res16"
	bottom: "conv35"
	top: "res17"
	name: "res17"
	type: "Eltwise"
}

layer {
	bottom: "res17"
	top: "res17"
	name: "bn_res17"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res17"
	top: "res17"
	name: "bn_res17"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "res17"
	top: "res17"
	name: "res17_relu"
	type: "ReLU"
}

####----    ----####

#####------- Residual Inception Block 18 ---------#####

layer {
	bottom: "res17"
	top: "act35"
	name: "bn_conv36"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res17"
	top: "act35"
	name: "bn_conv36"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale36"
	type: "Scale"
	bottom: "act35"
	top: "act35"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act35"
	top: "act35"
	name: "conv36_relu"
	type: "ReLU"
}

layer {
	bottom: "act35"
	top: "inception18_conv1x1"
	name: "inception18_conv1x1"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception18_conv1x1"
	top: "inception18_conv1x1"
	name: "inception18_conv1x1_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act35"
	top: "inception18_3x3_reduce"
	name: "inception18_3x3_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception18_3x3_reduce"
	top: "inception18_3x3_reduce"
	name: "inception18_3x3_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act35"
	top: "inception18_5x5_reduce"
	name: "inception18_5x5_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		pad: 2
		stride: 1
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception18_5x5_reduce"
	top: "inception18_5x5_reduce"
	name: "inception18_5x5_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act35"
	top: "inception18_pool"
	type: "Pooling"
	name: "inception18_pool"
	pooling_param {
		pool: MAX
		kernel_size: 3
		stride:1
		pad: 1
	}
}

layer {
	bottom: "inception18_3x3_reduce"
	top: "inception18_3x3"
	name: "inception18_3x3"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception18_3x3"
	top: "inception18_3x3"
	name: "inception18_3x3_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception18_5x5_reduce"
	top: "inception18_5x5"
	name: "inception18_5x5"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 5
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception18_5x5"
	top: "inception18_5x5"
	name: "inception18_5x5_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception18_pool"
	top: "inception18_pool_proj"
	name: "inception18_pool_proj"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception18_pool_proj"
	top: "inception18_pool_proj"
	name: "inception18_pool_proj_ReLU"
	type: "ReLU"
}

layer {
  name: "inception18_output"
  type: "Concat"
  bottom: "inception18_conv1x1"
  bottom: "inception18_3x3"
  bottom: "inception18_5x5"
  bottom: "inception18_pool_proj"
  top: "inception18_output"
}

layer {
	bottom: "inception18_output"
	top: "res18_inc_output"
	name: "res18_inc_output"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		#bias_filler {
		#	type: "constant"
		#	value: 0.2
		#}
	}
}

layer {
	bottom: "res17"
	bottom: "res18_inc_output"
	top: "res18"
	name: "res18"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 19 ---------#####

layer {
	bottom: "res18"
	top: "conv38"
	name: "conv38"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv38"
	top: "conv38"
	name: "bn_conv38"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv38"
	top: "conv38"
	name: "bn_conv38"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "conv38"
	top: "conv38"
	name: "conv38_relu"
	type: "ReLU"
}

layer {
	bottom: "conv38"
	top: "conv39"
	name: "conv39"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res18"
	bottom: "conv39"
	top: "res19"
	name: "res19"
	type: "Eltwise"
}

layer {
	bottom: "res19"
	top: "res19"
	name: "bn_res19"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res19"
	top: "res19"
	name: "bn_res19"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom:"res19"
	top: "res19"
	name: "res19_relu"
	type: "ReLU"
}

####----    ----####

#####------- Residual Inception Block 20 ---------#####

layer {
	bottom: "res19"
	top: "act39"
	name: "bn_conv40"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res19"
	top: "act39"
	name: "bn_conv40"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale40"
	type: "Scale"
	bottom: "act39"
	top: "act39"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act39"
	top: "act39"
	name: "conv40_relu"
	type: "ReLU"
}

layer {
	bottom: "act39"
	top: "inception20_conv1x1"
	name: "inception20_conv1x1"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception20_conv1x1"
	top: "inception20_conv1x1"
	name: "inception20_conv1x1_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act39"
	top: "inception20_3x3_reduce"
	name: "inception20_3x3_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 64
		kernel_size: 1
		stride: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception20_3x3_reduce"
	top: "inception20_3x3_reduce"
	name: "inception20_3x3_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act39"
	top: "inception20_5x5_reduce"
	name: "inception20_5x5_reduce"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 16
		pad: 2
		stride: 1
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception20_5x5_reduce"
	top: "inception20_5x5_reduce"
	name: "inception20_5x5_reduce_ReLU"
	type: "ReLU"
}

layer {
	bottom: "act39"
	top: "inception20_pool"
	type: "Pooling"
	name: "inception20_pool"
	pooling_param {
		pool: MAX
		kernel_size: 3
		stride:1
		pad: 1
	}
}

layer {
	bottom: "inception20_3x3_reduce"
	top: "inception20_3x3"
	name: "inception20_3x3"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception20_3x3"
	top: "inception20_3x3"
	name: "inception20_3x3_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception20_5x5_reduce"
	top: "inception20_5x5"
	name: "inception20_5x5"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 5
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception20_5x5"
	top: "inception20_5x5"
	name: "inception20_5x5_ReLU"
	type: "ReLU"
}

layer {
	bottom: "inception20_pool"
	top: "inception20_pool_proj"
	name: "inception20_pool_proj"
	type: "Convolution"
	param {
		lr_mult: 1
		decay_mult: 1
	}
	param {
		lr_mult: 2
		decay_mult: 0
	}
	convolution_param {
		num_output: 32
		kernel_size: 1
		weight_filler {
			type: "xavier"
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "inception20_pool_proj"
	top: "inception20_pool_proj"
	name: "inception20_pool_proj_ReLU"
	type: "ReLU"
}

layer {
  name: "inception20_output"
  type: "Concat"
  bottom: "inception20_conv1x1"
  bottom: "inception20_3x3"
  bottom: "inception20_5x5"
  bottom: "inception20_pool_proj"
  top: "inception20_output"
}

layer {
	bottom: "inception20_output"
	top: "res20_inc_output"
	name: "res20_inc_output"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		weight_filler {
			type: "gaussian"
			std: 0.12
		}
		#bias_filler {
		#	type: "constant"
		#	value: 0.2
		#}
	}
}

layer {
	bottom: "res19"
	bottom: "res20_inc_output"
	top: "res20"
	name: "res20"
	type: "Eltwise"
}

####----    ----####

#####------- Residual Block 21 ---------#####

layer {
	bottom: "res20"
	top: "conv42"
	name: "conv42"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "conv42"
	top: "conv42"
	name: "bn_conv42"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "conv42"
	top: "conv42"
	name: "bn_conv42"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom: "conv42"
	top: "conv42"
	name: "conv42_relu"
	type: "ReLU"
}

layer {
	bottom: "conv42"
	top: "conv43"
	name: "conv43"
	type: "Convolution"
	param {
		lr_mult: 1
	}
	param {
		lr_mult: 2
	}
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.06
		}
		bias_filler {
			type: "constant"
			value: 0.2
		}
	}
}

layer {
	bottom: "res20"
	bottom: "conv43"
	top: "res21"
	name: "res21"
	type: "Eltwise"
}

layer {
	bottom: "res21"
	top: "res21"
	name: "bn_res21"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res21"
	top: "res21"
	name: "bn_res21"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	bottom:"res21"
	top: "res21"
	name: "res21_relu"
	type: "ReLU"
}

####----    ----####

# Block 22 -#

layer {
	bottom: "res21"
	top: "act43"
	name: "bn_conv44"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
		phase: TRAIN
	}
}

layer {
	bottom: "res21"
	top: "act43"
	name: "bn_conv44"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	include {
		phase: TEST
	}
}

layer {
	name: "BN_scale44"
	type: "Scale"
	bottom: "act43"
	top: "act43"
	scale_param {
		bias_term: true
	}
}

layer {
	bottom: "act43"
	top: "act43"
	name: "conv44_relu"
	type: "ReLU"
}

layer {
	bottom: "act43"
	top: "avg_pool"
	name: "avg_pool"
	type: "Pooling"
	pooling_param {
		pool: AVE
		global_pooling: true
	}
}

layer {
	bottom:"avg_pool"
	top: "fc10"
	name: "fc10"
	type: "InnerProduct"
	inner_product_param {
		num_output: 10
		weight_filler {
			type: "gaussian"
			std: 0.1
		}
		bias_filler {
			type: "constant"
		}
	}
}


layer {
	name: "accuracy"
	type: "Accuracy"
	bottom: "fc10"
	bottom: "label"
	top: "accuracy"
}

layer {
	name: "loss"
	type: "SoftmaxWithLoss"
	bottom: "fc10"
	bottom: "label"
	top: "loss"
}
